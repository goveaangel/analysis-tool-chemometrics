# pages/5_üß¨_Clustering.py
import streamlit as st
import numpy as np

from backend.clustering import (
    run_kmeans,
    run_hierarchical,
    cluster_scatter_pcs,
    dendrogram_from_pcs,
    cluster_summary_table,
)

st.title("üß¨ Clustering (K-means & Jer√°rquico)")
st.markdown(
    """
En esta secci√≥n agrupamos las **muestras** en cl√∫sters usando sus coordenadas en el
espacio de **componentes principales (PCs)**.

La idea es encontrar grupos de muestras que se comportan de forma **similar** en las
variables originales (temperaturas, concentraciones, etc.), pero trabajando en un
espacio reducido y m√°s interpretable.
"""
)

st.caption(
    "Primero se aplica PCA para reducir la dimensi√≥n; despu√©s, sobre esos scores de PCA, "
    "se ejecutan los algoritmos de clustering."
)

# ============================
# 0. Recuperar datos base
# ============================

clean_data = st.session_state.get("clean_data", None)
raw_df_state = st.session_state.get("raw_df", None)
raw_data_state = st.session_state.get("raw_data", None)

if clean_data is not None:
    raw_df = clean_data
elif raw_df_state is not None:
    raw_df = raw_df_state
elif raw_data_state is not None:
    raw_df = raw_data_state
else:
    raw_df = None

if raw_df is None:
    st.warning(
        "No se encontraron datos en sesi√≥n. "
        "Primero carga y preprocesa un dataset en las pesta√±as anteriores."
    )
    st.stop()

# ============================
# 0.5 Recuperar info de PCA
# ============================

pca_info = st.session_state.get("pca_info", None)

if pca_info is None or "scores" not in pca_info:
    st.info(
        "Ve a la pesta√±a **üìâ PCA**, ejecuta el an√°lisis y presiona "
        "el bot√≥n **'‚úÖ Guardar informaci√≥n PCA'** antes de usar clustering."
    )

scores = pca_info["scores"]

if scores is None or scores.empty:
    st.error("Los scores de PCA est√°n vac√≠os. Revisa la configuraci√≥n en la pesta√±a de PCA.")
    st.stop()

# Detectar columnas de PCs
pc_cols = [c for c in scores.columns if c.upper().startswith("PC")]
if len(pc_cols) < 2:
    st.warning("Se requieren al menos PC1 y PC2 para visualizar el clustering.")
    st.stop()

# Usaremos hasta las primeras 3 PCs para el modelo (si existen)
pc_model_cols = pc_cols[: min(3, len(pc_cols))]
pc_plot_x = pc_model_cols[0]
pc_plot_y = pc_model_cols[1] if len(pc_model_cols) > 1 else pc_model_cols[0]

# ============================
# 1. Opciones de clustering
# ============================
st.subheader("1. Opciones de clustering")

st.markdown(
    """
Selecciona el tipo de **algoritmo de agrupamiento** que quieres usar:

- **K-means**: crea cl√∫sters ‚Äúesf√©ricos‚Äù alrededor de centroides.
- **Cl√∫ster jer√°rquico**: construye una jerarqu√≠a (√°rbol) de agrupamientos.
"""
)

method = st.radio(
    "M√©todo de clustering:",
    options=["K-means", "Cl√∫ster jer√°rquico"],
    help=(
        "K-means busca k grupos compactos en el espacio de las PCs.\n"
        "El clustering jer√°rquico construye un √°rbol de similitud entre muestras."
    ),
)

if method == "K-means":
    st.markdown("#### Par√°metros de K-means")
    st.caption(
        "K-means reparte las muestras en k grupos, de manera que cada muestra quede "
        "cerca del centro (centroide) de su cl√∫ster."
    )

    k = st.slider(
        "N√∫mero de cl√∫sters (k)",
        min_value=2,
        max_value=10,
        value=3,
        help="N√∫mero de grupos que quieres formar en los datos.",
    )
    init_reps = st.number_input(
        "N√∫mero de inicializaciones (repeticiones)",
        min_value=1,
        max_value=50,
        value=10,
        help=(
            "K-means depende del punto de partida. Probar varias inicializaciones "
            "ayuda a encontrar una soluci√≥n m√°s estable."
        ),
    )
    st.caption("M√°s inicializaciones pueden dar una soluci√≥n m√°s estable de K-means.")

    # Ejecutar K-means en el backend
    kmeans_result = run_kmeans(
        scores_df=scores[pc_model_cols],
        n_clusters=k,
        n_init=init_reps,
        random_state=42,
    )
    labels = kmeans_result["labels"]

else:
    st.markdown("#### Par√°metros del clustering jer√°rquico")
    st.caption(
        "El clustering jer√°rquico no parte de un n√∫mero fijo de grupos: construye un √°rbol "
        "de similitud y luego se corta ese √°rbol para obtener k cl√∫sters."
    )

    linkage = st.selectbox(
        "Tipo de liga (linkage)",
        options=["ward", "complete", "average", "single"],
        index=0,
        help=(
            "ward: minimiza el aumento de varianza dentro de los cl√∫sters.\n"
            "complete: usa la distancia m√°xima entre puntos de dos cl√∫sters.\n"
            "average: usa la distancia promedio.\n"
            "single: usa la distancia m√≠nima (tiende a generar cadenas)."
        ),
    )
    n_clusters = st.slider(
        "N√∫mero de cl√∫sters (para jer√°rquico)",
        min_value=2,
        max_value=10,
        value=3,
        help="N√∫mero de grupos que se cortar√°n a partir del dendrograma.",
    )
    st.caption("El n√∫mero de cl√∫sters se usar√° al cortar el dendrograma.")

    # Ejecutar clustering jer√°rquico
    hier_result = run_hierarchical(
        scores_df=scores[pc_model_cols],
        n_clusters=n_clusters,
        linkage=linkage,
        metric="euclidean",
    )
    labels = hier_result["labels"]

st.markdown("---")

# ============================
# 2. Visualizaci√≥n de cl√∫sters
# ============================
st.subheader("2. Visualizaci√≥n de cl√∫sters en espacio de PCs")

st.markdown(
    """
El siguiente gr√°fico muestra las **muestras proyectadas en las PCs** (por ejemplo PC1 vs PC2),
coloreadas seg√∫n el cl√∫ster al que pertenecen.

- Puntos **del mismo color** pertenecen al **mismo cl√∫ster**.
- Puntos **cercanos** indican muestras con comportamiento similar.
- Grupos separados sugieren **patrones diferentes** de proceso o calidad.
"""
)

col1, col2 = st.columns(2)

with col2:
    st.markdown("#### Par√°metros gr√°ficos")
    palette = st.selectbox(
        "Paleta de colores",
        options=["Viridis", "Plasma", "Cividis", "Categorical"],
        help="Cambia la paleta de colores para diferenciar mejor los cl√∫sters.",
    )
    point_size = st.slider(
        "Tama√±o de puntos", 3, 20, 8, help="Controla el tama√±o de cada muestra en el scatter."
    )
    alpha = st.slider(
        "Transparencia (alpha)",
        0.1,
        1.0,
        0.8,
        help="Valores m√°s bajos hacen los puntos m√°s transparentes (√∫til si hay muchos).",
    )

with col1:
    st.markdown("#### Scatter plot de cl√∫sters")
    fig_scatter = cluster_scatter_pcs(
        scores_df=scores[pc_model_cols],
        labels=labels,
        palette=palette,
        point_size=point_size,
        alpha=alpha,
        pc_x=pc_plot_x,
        pc_y=pc_plot_y,
    )
    st.plotly_chart(fig_scatter, use_container_width=True)

st.caption(
    f"Cada punto es una muestra en el plano formado por {pc_plot_x} y {pc_plot_y}. "
    "Los colores indican a qu√© cl√∫ster pertenece cada muestra."
)

st.markdown("---")

# ============================
# 3. Dendrograma
# ============================
st.subheader("3. Dendrograma (para clustering jer√°rquico)")

st.markdown(
    """
El **dendrograma** muestra c√≥mo se van fusionando las muestras en cl√∫sters
cuando aumenta el nivel de similitud. Es √∫til para:

- Ver si hay grupos bien separados.
- Decidir un n√∫mero razonable de cl√∫sters.
"""
)

if method == "Cl√∫ster jer√°rquico":
    fig_dend = dendrogram_from_pcs(scores_df=scores[pc_model_cols])
    st.plotly_chart(fig_dend, use_container_width=True)
    st.caption(
        "Las uniones m√°s bajas indican muestras muy similares. Cortar el √°rbol a una cierta altura "
        "equivale a elegir un n√∫mero de cl√∫sters."
    )
else:
    st.caption("Cambia a 'Cl√∫ster jer√°rquico' para ver el dendrograma.")

st.markdown("---")

# ============================
# 4. M√©tricas de calidad
# ============================
st.subheader("4. M√©tricas de calidad del clustering")

st.markdown(
    """
Estas m√©tricas ayudan a evaluar qu√© tan ‚Äúbien definidos‚Äù est√°n los cl√∫sters:

- **Silhouette score**: mide qu√© tan separado est√° cada cl√∫ster de los dem√°s.
  Valores cercanos a 1 indican cl√∫sters compactos y bien separados; cercanos a 0,
  cl√∫sters poco claros.
- **Inercia (SSE)**: solo para K-means. Es la suma de distancias al centroide;
  valores m√°s bajos indican cl√∫sters m√°s compactos (pero siempre comparando con el mismo dataset).
"""
)

if method == "K-means":
    sil = kmeans_result.get("silhouette", float("nan"))
    inertia = kmeans_result.get("inertia", float("nan"))
    st.write(f"Silhouette score: **{sil:.3f}**")
    st.write(f"Inercia (SSE): **{inertia:.2f}**")
else:
    sil = hier_result.get("silhouette", float("nan"))
    st.write(f"Silhouette score: **{sil:.3f}**")

st.caption(
    "Estas m√©tricas no sustituyen el criterio del experto, pero permiten comparar configuraciones "
    "diferentes de cl√∫sters (por ejemplo, distintos valores de k)."
)

st.markdown("---")

# ============================
# 5. Resumen de cl√∫sters
# ============================
st.subheader("5. Resumen de cl√∫sters")

st.markdown(
    """
Aqu√≠ se muestra un resumen de **tama√±o de cada cl√∫ster** y las **medias de las variables**
dentro de cada grupo. Esto ayuda a interpretar qu√© caracteriza a cada cl√∫ster:

- Cl√∫sters con **mayor promedio** en cierta variable pueden asociarse, por ejemplo, a
  condiciones de proceso m√°s calientes, mayores concentraciones, etc.
- Diferencias entre cl√∫sters sugieren **reg√≠menes de operaci√≥n** o **tipos de muestra** distintos.
"""
)

if raw_df is None:
    st.caption("Conecta el DataFrame original en sesi√≥n para mostrar el resumen de cl√∫sters.")
else:
    summary = cluster_summary_table(original_df=raw_df, labels=labels)

    st.markdown("**Tama√±o de cada cl√∫ster**")
    st.dataframe(summary["sizes"].to_frame("n_observaciones"))

    st.markdown("**Medias de variables num√©ricas por cl√∫ster**")
    st.dataframe(summary["means"])

# ============================
# 6. Guardar informaci√≥n de clustering en session_state
# ============================

cluster_info = {
    "method": method,
    "pc_model_cols": pc_model_cols,
    "labels": labels,
    "n_obs": len(labels),
}

if method == "K-means":
    cluster_info["n_clusters"] = int(k)
    cluster_info["silhouette"] = float(sil) if not np.isnan(sil) else None
    cluster_info["inertia"] = float(inertia) if not np.isnan(inertia) else None
else:
    cluster_info["n_clusters"] = int(n_clusters)
    cluster_info["silhouette"] = float(sil) if not np.isnan(sil) else None
    cluster_info["linkage"] = linkage

cluster_info["cluster_sizes"] = summary["sizes"]
cluster_info["cluster_means"] = summary["means"]

cluster_figs = {
    "scatter": fig_scatter,
}
if method == "Cl√∫ster jer√°rquico" and "fig_dend" in locals():
    cluster_figs["dendrogram"] = fig_dend

st.markdown("---")
st.subheader("6. Guardar informaci√≥n de clustering")

st.markdown(
    """
Al guardar, esta pesta√±a almacena en la sesi√≥n:

- La configuraci√≥n del algoritmo (m√©todo, n√∫mero de cl√∫sters, linkage, etc.).
- Las etiquetas de cl√∫ster para cada muestra.
- El resumen de tama√±os y medias.
- Las figuras principales (scatter y dendrograma).

Esto permitir√° reutilizar estos resultados en la pesta√±a de **Resultados** o en un reporte.
"""
)

if st.button("‚úÖ Guardar informaci√≥n de clustering", use_container_width=True):
    try:
        st.session_state["cluster_info"] = cluster_info
        st.session_state["cluster_figs"] = cluster_figs
        st.success("Informaci√≥n y gr√°ficas de clustering guardadas correctamente.")
    except Exception as e:
        st.error(f"Error al guardar la informaci√≥n de clustering: {e}")